\documentclass[11pt, english, screen]{report-rd-info}
   % - 12pt:  can be preferable to read the report on small screens, ask your supervisors
   % - screen:  to be removed in order to obtain a classical report
\usepackage[latin1]{inputenc}
   % - latin9, utf8, etc.
\usepackage[T1]{fontenc}

% some definitions for the actual contents
\usepackage{enumerate}
\usepackage{color}
\usepackage{amsmath, amssymb}
\usepackage{algorithm,algpseudocode}
%\usepackage{algorithm}
%\usepackage{algorithmic}

\begin{document}

\title{A Polytech Research Report}
\subtitle{A Model and Short Guide}

\authorA{Julian}{Tanke}
\authorB{}{}
\supervisor{Pascal}{Molli}
\cosupervisor{Brice}{Nedelec}
   % In case, there are more than two supervisors, use the following trick:
   %    \cosupervisor{Jean}{Cadre \& {\normalfont Still} Another}
\coordinator{José}{Martinez}
\institution{LINA}
   % - LINA when you're supervised by members of the research teams GRIM or COD (may be some others);
   % - IRCCyN when youre supervised by members of the research team IVC;
   % - XXX when supervised by another organism
   %   (In that case, you have to provide, in the "logos" directories, the files named: XXX.pdf -- if not XXX.jpeg or XXX.png -- for pdflatex *and* XXX.eps for latex);
   % - otherwise comment it
\theme{\'Equipe GRIM}
   % - optionally provide it when an institution has been declared (GRIM, COD or IVC for the local research teams)
   % - otherwise comment it
%\coinstitution{Centre national de la recherche scientifique}{CNRS}{1.7cm}
   % - if you need to add a partner
   % - the logo must be provided, e.g., CNRS.pdf here
   % - the third parameter allows one to control the width of the logo in order to make
   %   it look of the same size of the one from the university of nantes and possibly the laboratory
\date{November 15, 2014}
   % - do not had un 0 in front of the first to ninth day of a mont!
   % - you can altogether ignore the day.

%-------------------------------------------------------------------------------------------------------------

\begin{abstract}
%\small % Comment it out should the abstract by slightly too long to fit in the page.
   As the name suggests, the abstract is a very short but informative piece of information about everything you did in this work, i.e., successively the description of the problem at hand, the objectives, the main point of the state-of-the-art, the choices made, the conceptual developments, the conducted experiments, results and interpretations, the new issues.

   It is the last thing to write!
\end{abstract}

\begin{classification}
%\small % Idem
   Bibliographic indexing is required. Use the ACM thesaurus:  See \url{http://www.acm.org/about/class/}. (The following example is based on the 1998 version, where general terms and additional key words are optional.)

   \category{H.2.8}{Database Applications}{Image databases}
   \category{H.3.3}{Information Search and Retrieval}{Clustering, Information filtering, Relevance feedback}
   \category{H.3.7}{Digital Libraries}{User issues}
   \category{I.5.3}{Clustering}{Algorithms, Similarity measures}
   \category{I.4.10}{Image Representation}{Statistical, Multidimensional}
   \terms{Algorithms, Performances, Experiments, Human factors, Verification.}
   \keywords{Content-based image retrieval system, Classification, Feedback loop, Supervised learning.}
\end{classification}

\maketitle

%--------------------------------------------------------------------------------

\begin{acknowledgements}
   The usual place of acknowledgements, if this pleases you or if the work has been conducted as part of a larger endeavour.
\end{acknowledgements}

%--------------------------------------------------------------------------------

\newpage

\tableofcontents

%--------------------------------------------------------------------------------

\chapter*{Preface}
\addcontentsline{toc}{chapter}{Preface}

TODO
%--------------------------------------------------------------------------------

\chapter{Introduction}

Many efforts have been devoted to establish a data connection between browsers using the WebRTC API\footnote{http://w3c.github.io/webrtc-pc/}. 
Services like PeerCDN\footnote{https://peercdn.com/}, webtorrent\footnote{https://github.com/feross/webtorrent} or Sharefest\footnote{https://www.sharefest.me/} demonstrate how decentralized services now can be deployed easily in web browsers.
This drastically improves the user experience as they can download torrents as easy as watching a youtube video.
However, current solutions do not provide a scalable broadcast.
This, however, is essential for other applications such as distributed collaborative editors or distributed social networks.
Traditionally, gossip protocols are used to implement broadcast in decentralized infrastructure.
This protocols have been used in a various number of large scale systems serving an array of problem settings including information dissemination \cite{Demers:1987:EAR:41840.41841}, information aggregation \cite{Jelasity:2005:GAL:1082469.1082470} and network management \cite{conf/dsom/VoulgarisS03}.
Peers are highly autonomous and independent, which allows the algorithms to be simple when compared to hierarchical approaches.
This protocols can easily scale to millions of peers which can join and leave without significantly disrupting the service.

\section{Statement of the problem}

This raises the problem of deploying gossip algorithms on WebRTC.
Many gossip protocols build up upon the premise that the peers can interconnect easily with each other and, as such, constantly connect to new sets of peers\cite{Voulgaris05cyclon:inexpensive}\cite{Jelasity:2004:PSS:1045658.1045666}.
Unfortunately, certain efforts must be taken to establish a peer-to-peer connection with WebRTC:
as entities in WebRTC cannot directly address each other due to the network layout of the Internet, a handshake, consisting of an offer by one client and a responding answer by the other, must be performed.
This process must be hoist by a well-known service in between, which we will call the \emph{signaling service}.
Furthermore, the handshake radically changes the communication complexity as connecting to new peers becomes more expansive and error-prone.

\section{Objectives}

In this report we evaluate the cost of two well-known gossip algorithms, CYCLON\cite{Voulgaris05cyclon:inexpensive} and SCAMP\cite{Ganesh:2001:SPL:648089.747488}, in a WebRTC infrastructure.
We provide a technique to minimize the number of connections to the well-known signaling service, and, 
additionally, we propose a new algorithm that merges the advantages of CYCLON and SCAMP regarding network topology and robustness towards WebRTC.

\section{Work achieved}

We show that CYCLON can be easily deployed in a WebRTC environment as it only communicates with other nodes in close proximity reducing the handshaking overhead.
We also show that the lease-mechanism in SCAMP can be significantly disturbed under churn or network failure.
We provide a WebRTC library\footnote{https://github.com/justayak/handshake} that allows nodes inside a WebRTC network to host connections between each other without the need of an external service. This minimizes the number of connections towards the signaling service as it is only needed to introduce a new node to an existing network.
Furthermore, we propose an algorithm that combines the good properties of CYCLON and SCAMP and removes some of their problems, namely: SCAMP is used to enter or remove a node from the network, thus providing a good random starting distribution and an adaptive partial view size, but use CYCLON to balance the graph afterwards to exploit its close-proximity exchanges.

\section{Contribution}

Gossip protocols that are designed for the internet have already been introduced by \cite{Ganesh:2003:PMM:642778.642782} and\cite{Voulgaris03arobust}.
However, this protocols assume that a connection can be established with direct addressing, ignoring the limitations mentioned above.
On the other side there are implementations of peer-to-peer networks on top of WebRTC\footnote{http://peerjs.com/} already available. 
Nonetheless they lack truly massive scalability as they rely on a single centralized signaling service to host and maintain the network.
Our contribution is an algorithm that is truly scalable in a WebRTC environment.

\section{Report organisation}

The remainder of this paper is structured as follows: 
Chapter~\ref{chap:Motiv} explains the technology in more depth and provides an example application. 
Chapter~\ref{chap:StateOfTheArt} studies the gossip protocols CYCLON and SCAMP. 
In Chapter~\ref{chap:Proposals} we will introduce an example application.
Furthermore we will outline the requirements for a handshaking gossip protocol.
Chapter~\ref{chap:Experiments} follows a development, experiment, and analysis path in order to quantify the theoretical results.
Finally, the conclusion summarises the work and introduce new research issues that are worth pursuing.

%-------------------------------------------------------------------------------------------------------------
\chapter{Background and Motivation}
\label{chap:Motiv}

\section{WebRTC}

Web Real-Time Communications (WebRTC) is a client-side API to enable Real-Time Communications in web browsers \cite{webrtc}.
It is an implementation of SRTP\footnote{Secure Real-time Transport Protocol} with an SDP\footnote{Sockets Direct Protocol} control mechanism on top that can use STUN, TURN and ICE for NAT traversal.

\textit{These APIs should enable building applications that can be run inside a browser, requiring no extra downloads or plug-ins, that allow communication between parties using audio, video and supplementary real-time communication, without having to use intervening servers (unless needed for firewall traversal, or for providing intermediary services).}

As we are interested in sending arbitrary data between peers we will focus on the DataChannel API.
Unfortunately WebRTC cannot create a connection between peers without a signaling service. 
That means that we need some sort of communication exchange (Handshake) prior to the direct peer-to-peer connection.
Figure~\ref{fig:webrtc} demonstrates how a connection is established in WebRTC:

\begin{enumerate}
    \item{Alice needs to find out her public Internet address and her network setup (Routers, Firewall).
To obtain this information, she queries a well-known STUN-Server.}
    \item{To establish a connection with Bob, she now needs to create an offer and send it to the signaling service.}
    \item{The signaling service selects Bob and forwards Alice's offer to him.}
    \item{We assume, that Bob already knows his network setup (as he called a STUN-Server before).
Bob accepts the request that Alice sends to him and wants to communicate. To do so he must create an answer and send it back to Alice. As Bob does not know how to connect to Alice yet, he sends the answer to the signaling service instead.}
    \item{The signaling service sends the answer back to Alice.}
    \item{Upon receiving Bob's positive answer, Alice sends a description of how the communication will be done and how Bob can send data to her. As she does not know how to directly connect to Bob yet, she sends this information to the signaling service.}
    \item{The signaling service forwards Alice's connection information to Bob.}
    \item{Bob checks if he can communicate in any way that Alice suggested, and, if he can, he describes how to connect directly to him. Again, this message is send to Alice through the signaling service.}
    \item{Alice gets the information from Bob and establishes a link to him. From now on they can communicate directly with each other. }
\end{enumerate}

\begin{figure}
    \centering
    \includegraphics[width=9cm]{Images/WebRTC}
    \caption{Examplary WebRTC connection}
    \label{fig:webrtc}
\end{figure}

\section{Massive Collaborative Editing}

One application for a gossip-based WebRTC network is a massive collaborative editor \cite{nedelec:hal-00921633}\cite{MassCollab} that runs in the web browser.
Unlike current solutions such as Google Docs, Microsoft Word Online or Etherpad we want to support millions of users on one document (e.g. Google Docs only allows 50 users to work on one document).
\cite{MassCollab} describes how parallel editing can scale well with the number of users, implied that some sort of broadcast exists.
However, no assumptions are made about how this broadcast is done.
A centralized service or a fully connected graph do not scale well with the user count.
Instead, using the proposed gossip-based peer-to-peer protocol for WebRTC will make the application more scalable and robust.

%-------------------------------------------------------------------------------------------------------------

% \part{State-of-the-Art} % Comment it out if the state-of-the-art requires several chapters.
                          % Most often, you'll then have a presentation chapter followed by a critical synthesis chapter.
                          % In that case, you must commen tour your work part, hereafter.
% \label{part:StateOfTheArt}

\chapter{State of the Art}
\label{chap:StateOfTheArt}

This chapter introduces fundamental algorithms and concepts. 

\section{Gossip Protocol}

Gossip, also revered to as \emph{epidemic dissemination}, is a  communication protocol initially inspired by observing of how gossips spread in social networks or how diseases spread over a population.
It trades reliability guarantees against scalability properties \cite{Eugster:2003:LPB:945506.945507} and it has been applied to various large scale systems, with the purpose of information dissemination \cite{Demers:1987:EAR:41840.41841}, information aggregation \cite{Jelasity:2005:GAL:1082469.1082470}, network management \cite{conf/dsom/VoulgarisS03} and many more.

The basic idea behind gossip works as follows:
a network is a graph $G=(V,E)$ where $V=\{1,...,n\}$ is a set of $n$ nodes.
Let $E \subset V \times V$ denote neighboring\footnote{In this paper, nodes are considered neighbors if they are directly connected to each other} nodes and let $d_i$ denote the degree of node $i$ in $G$ where 
$d_i$ is constrained by the configuration parameter $c \in \mathbb{Z}_{>0}$ which is called Fanout.
The Fanout defines the number of nodes that are selected when a message is broadcast from a node.
A high value generates a lot of redundant messages while being more fault tolerant and reliable. 
$V$ and $E$ constantly change as nodes leave and join the network and nodes update there neighbors to maintain a uniform distribution.

Assuming a node $i$ wants to broadcast a message $m$ - It sends $m$ to its $d_i$ neighboring nodes. 
A receiving node $j$ evaluates if it already knows $m$ \cite{Koldehofe03buffermanagement} - and if not, it will repeat the previous procedure: broadcast to its $d_j$ neighboring nodes and so forth. 
Usually three types of epidemic dissemination of messages can be distinguished:
\begin{itemize}
    \item \textbf{Push:} When receiving a message, a node sends it to all other nodes in its view.
    \item \textbf{Pull:} A node periodically queries one random other node to check for messages it has not received yet.
    \item \textbf{Push-Pull:} A node sends a message to another random peer and, additionally, queries said peer for data.
\end{itemize}

When $n$ is very large, for a given node $i$ it applies that $d_i << n$.
This is necessary for scalability reasons as, otherwise, the list of neighbors might exhaust a nodes memory and maintaining the list in presence of churn\footnote{Nodes constantly join and leave the network} would be too expansive.
We will call $\mathcal{N}_i \equiv \{j\in V:(i,j)\in E\}$ the \textbf{partial view} of $i$.
The partial view should consist of a random sample of $V$.

\section{Peer Sampling Service}

The peer sampling service \cite{Jelasity:2004:PSS:1045658.1045666}, or, random peer sampling (RPS), is a membership protocol.
The purpose of RPS is to provide each peer with a \emph{uniform sample} of $V$ in a distributed and scalable manner.
It can be used in a variety of gossip-based protocols, for example in topology management \cite{Jelasity:2009:TGF:1570533.1570626}. 
The peer sampling service consists of a simple API:

\begin{itemize}
    \item{\textbf{init:}} Initializes the service on a given node if this has not been done before. This is implementation dependent.
    \item{\textbf{getPeer:}} Returns a peer address if the network contains more than one node. The returned address is a sample drawn from the group. This method can also be used to return multiple random peers, either by providing a paramter $n$ to the function or by simply calling the method multiple times.
\end{itemize}

There are two strategies to maintain partial views in peer sampling services \cite{Leitao_gossip-basedbroadcast} that will play an important role in our evaluation:

\begin{itemize}
    \item{\textbf{Reactive:} The partial view only changes when $V$ changes (Nodes join or leave) and remains stable otherwise.
An example algorithm is SCAMP \cite{Ganesh:2001:SPL:648089.747488}.}
    \item{\textbf{Cyclic:} The partial view is periodically updated every $\bigtriangleup T$ time units and membership information are exchanged with neighbors.
An example algorithm is CYCLON \cite{Voulgaris05cyclon:inexpensive}.}
\end{itemize}

\section{SCAMP}

The probabilistic scalable membership protocol (SCAMP)\cite{Ganesh:2001:SPL:648089.747488} is a reactive peer sampling service.
The size of its local views adapt automatically to a desired value of $(c+1)\log{n}$ where $c$ is a  parameter which specifies the degree of robustness to failure(\cite{Kermarrec:2003:PRD:766617.766623}, \emph{Theorem 1}).
It maintains two separated partial views\cite{Ganesh:2003:PMM:642778.642782}, one for receiving gossip messages (InView $\mathcal{N}^{in}$), one for sending gossip messages (PartialView $\mathcal{N}^{out}$).

If a new node $k$ wants to join the network $G(V,E)$ it needs to have one member $i \in V$ in $\mathcal{N}_k^{out}$ and send a subscription request to $i$.
On receiving a subscription request, $i$ forwards the new peer to all members of its own $\mathcal{N}_i^{out}$, and, additionally, creates $c$ copies of the new subscription and forwards them to randomly chosen nodes in $\mathcal{N}_i^{out}$.
On receiving a forwarded subscription for node $k$, a receiving node $j$ integrates $k$ into its $\mathcal{N}_j^{out}$ with probability $p$ which depends on the size of $\mathcal{N}_j^{out}$ ($p_i=\frac{1}{1+|\mathcal{N}_i^{out}|}$). 
If $j$ does not integrate $k$, it forwards it to another randomly chosen peer from its $\mathcal{N}_j^{out}$.
When a node $i$ decides to keep the subscription of a node $j$, it integrates $j$ into its $\mathcal{N}_i^{out}$ and notifies $j$ to put $i$ into its $InView_j$.
On leaving the network, the leaving node $j$ sends a \emph{replace request} containing a peer from its $\mathcal{N}_j^{out}$ to $|\mathcal{N}_j^{in}|-c$ peers in its $\mathcal{N}_j^{in}$ and a \emph{deleting request} to the remaining ones.
When a node $i$ receives the \emph{replace request} from $j$, it will replace $j$ for the sent peer in its $\mathcal{N}_i^{out}$.

A subscription has a finite lifetime called \emph{lease}\footnote{The lease is implementation dependent: it could be set individually or it could be set globally}.
When expired, the subscribed node will be removed from all PartialViews.
It is a nodes responsibility to resubscribe once its subscription expires.
This mechanic ensures that failed nodes will not remain in the network.
Furthermore, the lease mechanism rebalances the network making it more robust.
Indeed, when a peer joins the system, it only has one node in its partial view, which makes it vulnerable to failures.
However, when peers resubscribe, it adds the link to its inView and therefore, to others partial view.
Hence, even the new peers get subscription requests.

Pseudocode: \cite{Ganesh:2001:SPL:648089.747488}, Section 2.1
\begin{algorithm}
    \caption{Subscription management}
    \begin{algorithmic}[1]
        \Procedure{OnSubscribe}{$subscriber$}
        \For{each $peer$ in $\mathcal{N}^{out}$}
        \State send \textbf{forwardedSubscription} with $subscriber$ to $peer$
        \EndFor
        \For{each $peer$ in sample($\mathcal{N}^{out}$, $c$)}
        \State send \textbf{forwardedSubscription} with $subscriber$ to $peer$
        \EndFor
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}
    \caption{Handling of a forwarded subscription}
    \begin{algorithmic}[1]
        \Procedure{OnForwardedSubscription}{$subscriber$}
        \State $keep \gets$ randomChoiceBetween0and1()
        \State $keep \gets \lfloor (|\mathcal{N}^{out}| + 1) * keep \rfloor$
        \If{$keep \equiv 0 $ and $subscriber \notin \mathcal{N}^{out}$}
        \State 
        \State // potentially very expensive as the handshake must be traced over
        \State // possibly many hops
        \State $\mathcal{N}^{out} \gets \mathcal{N}^{out} \cup \{subscriber\}$
        \State
        \Else
        \State $peer \gets$ sample($\mathcal{N}^{out}$, $1$)
        \State send \textbf{forwardSubscription} with $subscriber$ to $peer$
        \EndIf
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

\subsection{Indirection}

In Scamp, good scaling behavior is ensured when new nodes select their entry point uniformly random among the existing members\footnote{\cite{Ganesh:2001:SPL:648089.747488}, 3.1}.
However, in reality this is seldom the case. Instead it can be expected that few nodes will be designated entrances into the network.
To ensure a random distribution under this circumstances SCAMP introduces \emph{indirection} where the initial entrance node forwards the subscribers request to a node that is approximately chosen at random among the existing nodes.
This is done by a random walk\footnote{the exact algorithm is out of the scope of this report} of length $\log{n}$ which is the expected diameter of the graph.

% +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++=++++++++++++++
% +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++=++++++++++++++
\section{CYCLON}

CYCLON \cite{Voulgaris05cyclon:inexpensive} is a cyclic peer sampling service.
Each peer maintains a partial view of size $c$ and repeatedly exchanges its view with a neighbor - this operation is called a shuffle.
The protocol works as follows\footnote{Enhanced Shuffling, described in \cite{Voulgaris05cyclon:inexpensive}}:

Every $\bigtriangleup T$ time unit a node $i$ executes the shuffle function:

\begin{enumerate}
    \item{Increase by one the age of all neighbors.}
    \item{Select neigbor $j$ with the highest age among all neighbors, and $l-1$\footnote{$1 \le l \le c$}} other random neighbors.
    \item{Replace $j$'s entry with a new enty of age 0 and with $i$'s address.}
    \item{Send the updated subset to peer $j$}
    \item{Receive from $j$ a subset of no more than $t$ of its own entries.}
    \item{Discard entries pointing at $j$ and entries already contained in $i$'s partial view.}
    \item{Update $i$'s partial view to include all remaining entries, by firstly using empty slots (if any), and secondly replacing entries among the ones sent to $j$}
\end{enumerate}

On receiving the shuffle request from $i$ at $j$, $j$ sends back a random subset of $l$ of its neighbors and updates its own partial view with the sent data but it does not increase the age of the items in the partial view.
When a node $i$ does not get a response from a node $j$ after it sent a shuffle request it will discard node $j$ from its partial view as it seems to be failed. 
Because of this, failed nodes will be removed from the network in bounded time.
As in SCAMP, if a node wants to join the network, it needs to know another node that is already part of it.

\begin{algorithm}[H]
    \caption{Active}
    \begin{algorithmic}[1]
        \While{termination condition not reached}
        \State wait $\bigtriangleup T$
        \State $partialView \gets$ increaseAge($partialView$)
        \State $peer \gets$ max(orderByAge($partialView$))
        \State $rand \gets $ sample($partialView \backslash \{peer\}$ , $l-1$) $\cup \{$[addr:$ownAddress$, age:$0$]$\}$
        \State send $rand$ to $peer$
        \State $otherRand \gets $ receive from $peer$
        \State $otherRand \gets otherRand \backslash \{partialView \cup \{[addr:ownAddress, age:*]\}\}$
        \State $partialView \gets partialView \backslash rand$
        \State
        \State // this part is very expensive with handshake
        \State $partialView \gets partialView \cup otherRand$
        \State
        \While{$|partialView| < c$}
        \State // shift removes the first element of an list
        \State $partialView \gets shift(orderByAge(rand))$
        \EndWhile
        \EndWhile
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
    \caption{Passive}
    \begin{algorithmic}[1]
        \Procedure{OnExchange}{$peer$, $otherRand$}
        \State $rand \gets$ sample($partialView$, $l$)
        \State send $rand$ to $peer$
        \State $otherRand \gets otherRand \backslash partialView$
        \State $partialView \gets partialView \backslash rand$
        \State
        \State // this part is very expensive with handshake
        \State $partialView \gets partialView \cup otherRand$
        \State
        \While{$|partialView| < c$}
        \State // shift removes the first element of an list
        \State $partialView \gets shift(orderByAge(rand))$
        \EndWhile
        \EndProcedure
    \end{algorithmic}
\end{algorithm}


% +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++=++++++++++++++
% +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++=++++++++++++++




% +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++=++++++++++++++
% +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++=++++++++++++++

\section{Synthesis}

The main goal for using gossip based algorithms with WebRTC is to allow the Network to scale to vast sizes.
To fulfill this properties the protocol needs to relay (mostly) on local information and make use of a partial view that adapts automatically to the full network size to guaranty efficient information dissemination.
Additionally, as the system needs to employ handshaking due to WebRTC, the protocol must reduce the number of messages needed to establish a connection between two nodes.
This is important as each additional node in between reduces the probability of successfully establish a connection.
This restriction implies that nodes for exchanging information should be chosen from the temporary close neighborhood.
Table~\ref{tab:Comparison} shows that the two introduced algorithms each provide one feature while lacking the other.

\hfill \break
\begin{tabular}{l | c r }
 properties & SCAMP & CYCLON \\
  \hline
  adaptive size & \textcolor{green}{Yes} & \textcolor{red}{No} \\
  close proximity to neighbors & \textcolor{red}{No} & \textcolor{green}{Yes} \\
  divergence speed & slow & fast \\
  \label{tab:Comparison}
\end{tabular}
\hfill \break

Furthermore, we want the algorithm to diverge all its partial view sizes to the optimal value as fast as possible. 
Here, CYCLON is clearly better as its $\bigtriangleup T$ can be much smaller than the lease time in SCAMP allows.

\section{Conclusion}

All of the mentioned algorithms have certain problems and limitations when handshaking is added.
In CYCLON the value of $\bigtriangleup T$ must be higher than the time the peers need to connect.
This could be implemented by setting $CONNECTION-TIMEOUT < \bigtriangleup T$.
This will increase the time a news will take to be fully disseminated into the network by constant time.
We show that, other than that, the protocol remains relatively stable and performs reliable.

Scamp, on the other hand, must employ more complex engineering as its connecting contract is much more complicated.
The added complexity for SCAMP is not constant but rather depending on the network size.
This results in SCAMP being more fragile which is even increased by its lease-mechanism. 


% +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++=++++++++++++++
% +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++=++++++++++++++


%--------------------------------------------------------------------------------

% \part{Proposals} % Commet it out if this has been done for the state-of-the-art
% \label{part:Proposals}

\chapter{Proposals}
\label{chap:Proposals}

Our research question states: \emph{What is the cheapest handshake gossip algorithm?}
We consider an algorithm to be cheaper than another, if, on average, it employs less handshakes.
This also counts the number of peers in an \emph{intermediate handshake}.
We consider a handshake to be \emph{intermediate} if a peer $i$ cannot directly hoist a connection between two nodes $a$ and $b$ but instead needs to apply $m, m < 0$ intermediate nodes to establish a connection.
This is necessary due to the requirement to reduce the connections to a centralized signaling server as much as possible and, instead, use the decentralized peer-to-peer network to carry out the signaling service, as soon as a node is member of the system.
Additionally, we want our partial view to stay adaptive towards the network size.

\section{Combining SCAMP and CYCLON}

We propose to combine SCAMP and CYCLON into one protocol to exploit both its advantages and to remove both its issues.
SCAMP will be used to introduce new peers into the network and to remove them if they wish to leave.
Instead of SCAMP`s lease mechanism CYCLON will take over and balance out the partial views.
As the CYCLON part cannot rely on constant values for $c$ and $l$ anymore those need to be calculated on the fly: $l = \max \{\left \lceil{|partialView|/2}\right \rceil, 1\}$. The partial view size can be changed whenever a shuffle is performed as the algorithm will adapt its size towards the neighbor it exchanges data with.

Suppose that node $a$ wants to exchange its partial view with node $b$ and that the graph is created with the previously described SCAMP algorithm:

\begin{enumerate}
    \item{Increase by one the age of all neighbors.}
    \item{Select neigbor $j$ with the highest age among all neighbors, and $l-1$ other random neighbors.}
    \item{Replace $j$'s entry with a new enty of age 0 and with $i$'s address.}
    \item{Send the updated subset to peer $j$}
    \item{Generate the new size of the partial views: $low = \left \lfloor{\frac{|a|+|b|}{2}}\right \rfloor $ and $high = \left \lceil{\frac{|a|+|b|}{2}}\right \rceil$\footnote{|a| = size of $a$`s partial view, respective for $b$} }
    \item{Set our new size to $high$ when $|a|$ is even, $low$ otherwise; perform the same for $|b|$.}
    \item{Receive from $j$ a subset of no more than $t$ of its own entries.}
    \item{Discard entries pointing at $j$ and entries already contained in $i$'s partial view.}
    \item{Update $i$'s partial view to include all remaining entries, by firstly using empty slots (if any), and secondly replacing entries among the ones sent to $j$. Here we will respect the newly calculated size for our partial view.}
\end{enumerate}

%--------------------------------------------------------------------------------
\section{Pseudocode}

TODO

\section{Connectivity}

As this protocol is basically CYCLON it also inherits CYCLONS connectivity property\footnote{\cite{Voulgaris05cyclon:inexpensive}, 3.1.} that states that, given a fail-free environment, the connectivity of the network is guaranteed.
That means that no node becomes disconnected as a result of a shuffling operation.
We show that even with the variable partial view size the graph stays connected when subject to an shuffle:
There are three corner cases that we must observe:

first: Both partial views are of the same parity. After the shuffle, both partial views will have the same size. Furthermore, each partial view will remove exactly the amount of nodes to fit in all receiving nodes into the newly sized partial view, thus no arc gets lost and the overall connectivity does not change.

second: The parity of the view sizes are different: The even view will take $high$ as new partial view size while the odd view will use $low$. As with the first case, no arc is lost as the sent and received data sums up perfectly.

third: One of the above, plus one or both views contain nodes that are sent by the other view, thus resulting in a drop of some duplicated nodes. This will not disconnect the graph either as it only occurs when there are multiple pointers towards a certain node, so even when one gets removed, others are still available.
However, the calculated partial view must be kept and used for future shuffles, otherwise the network would suffer from a constant drop of arcs which will deter its properties. 

%--------------------------------------------------------------------------------

%\part{Experiments and Results} % in case of several chapters, then name the chapters differently
%\label{part:Experiments}

\chapter{Experiments and Results}
\label{chap:Experiments}

When it is not possible to work only at the theoretical level, experiments will take place.  In Computer Science, this is most often through developing code then running experiments with it and analysing the output.

\section{Mean cluster}

\begin{figure}[H]
    \centering
    \includegraphics[width=8cm]{Images/statistics/cyclon_1000_c20/mean_cluster}
    \caption{mean clustering of the CYCLON protocol (no failure)}
    \label{fig:cluster_cyclon}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=8cm]{Images/statistics/cyclon_1000_c20/mean_cluster_fail_10}
    \caption{mean clustering of the CYCLON protocol (10\% failure)}
    \label{fig:cluster_cyclon2}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=8cm]{Images/statistics/cyclon_1000_c20/mean_cluster_fail_40}
    \caption{mean clustering of the CYCLON protocol (40\% failure)}
    \label{fig:cluster_cyclon3}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=8cm]{Images/statistics/scamp_1000_c2/cluster/scamp1}
    \caption{mean clustering of the SCAMP protocol (no failure)}
    \label{fig:cluster_scamp1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=8cm]{Images/statistics/scamp_1000_c2/cluster/scamp2}
    \caption{mean clustering of the SCAMP protocol (10\% failure)}
    \label{fig:cluster_scamp2}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=8cm]{Images/statistics/scamp_1000_c2/cluster/scamp3}
    \caption{mean clustering of the SCAMP protocol (30\% failure)}
    \label{fig:cluster_scamp3}
\end{figure}



\section{Experiment 1}

Be extremely precise when describing your experiments.  They must be reproducible by any reader deeply interested in your work.

You should describe all the hypotheses and constraints related to the manipulated data and the developed algorithms or used softwares.  Check them carefully in order not to draw false conclusion from bad inputs or erroneous processing!

In this part of the report, you should put forth \emph{synthetic results}, in the form of several tables and figures (e.g., See figure~\ref{fig:Courbes}%
\footnote{Urs Oswald, \emph{``Graphics in LaTeX 2$_\varepsilon$,''} March 2003, \url{http://www.ursoswald.ch}.}%
)

For the sake of completeness, these synthetic results must be supported by the base results from which they are derived.  These lengthy results have to be put into the appendices (e.g., See Appendix~\ref{app:Measures}).

\section{Experiment 2}

Etc.

\section{Conclusion}

The conclusion of this chapter (alternatively of this part) is normally the culmination of this research work.  All the quality of the work, along with its limitations, have to be emphasised.  Also, you can draw some personal conclusion on the way this study has been conducted and what could be done better should you have the chance to restart it anew.

%--------------------------------------------------------------------------------

\chapter{Conclusion}

By the end of the work, you should firstly summarise the main steps and key results of the study.  Then, you should describe the research directions that this work opens, both simple extensions and new endeavours.

\section{Summary}

Even if it is yet another repetition, it is convenient to summarise not the whole report but at least your own work and results, stressing their value.

\section{Outcomes}

The most valuable teachings of the work (there always have) must be emphasised.  Some can be personal.

\section{Research directions}

It is quite rare that a given work totally closes a topic!  Even in that case, it remains possible to introduce new research directions, more or less connected to the topic and the new state-of-the-art.  More generally, you can mention all and every question that has arisen during the course of your work.

%--------------------------------------------------------------------------------

\nocite{*} % to be removed, actual citations in the report must be necessary and sufficient (this is just to create a fake bibliography in the model)

\bibliography{rapport}

\listoffigures{}

\listoftables{}

\listofalgorithms{}

\appendix

\chapter{Quoting Correctly}
\label{ann:Citations}

When copying verbatim the text of some author, i.e., doing a copy-paste operation from an electronic document or simply rewriting it by hand, you must obey some rules.

\section{Short Quotations}

Short quotations are written << on-line >> but emphasised by being put:
\begin{enumerate}
   \item into italics;
   \item between quotes;
   \item followed by the reference to the original text from which it has been extracted.
\end{enumerate}

In that way, we could write \emph{``[s]i on est trop jeune, on ne juge pas bien [;] [s]i on est trop vieil, de même''}\footnote{if one is too young, one does not judge well;  so if one is too old} \cite{Pascal-1671}.

The rationale is to clearly give credit to the author.

\bigskip

In the previous example, notice that some parts of the text are put between squared brackets.
This are parts of the original text that have been slightly modified in order to fit the syntactic and grammatical rules of the whole sentence.
Here, that corresponds to an original sentence that has been transformed into a subordinate.

The most important of those marks is the ellipsis (unused here), denoted ``[\ldots]'.
It corresponds to a part of the text that has been removed.
The reason for doing that can be to avoid a digression from the main matter.
Nevertheless, omitting to inform the reader that the text has been purged is a means to lie to the reader and possibly to change the original meaning of the text, whether intentionally or not.

\section{Long Quotations}

Longer quotations -- from a few sentences to some paragraphs -- use a specific format, illustrated below.
The whole borrowed text is indented and still obeys the previous rules.

For instance, by taking the full original text of the previous example, we obtain:
\begin{quote}
   \emph{<< Si on est trop jeune, on ne juge pas bien. Si on est trop vieil, de même. Si on n'y songe pas assez, si on y songe trop, on s'entête, \& l'on ne peut trouver la vérité. >>}\footnote{If one is too young, one does not judge well;  so if one is too old.  If one does not think enough, or too much, one gets obstinate and cannot find the truth.} \cite{Pascal-1671}
\end{quote}

\section{Foreign Languages}

When the text is written in a foreign language, it must be kept into its original format, and the other rules are the same.
However, in addition, a translation should be given as a footnote (which can help to detect misunderstandings!\ldots).

\section{Figures}

Any kind of schema (figures, tables) belonging to someone else can only be copied with parcimony and by referencing the source in the legend.

\section{Plagiarism}
\label{ann:Plagiarism}

Any other usage of someone else production means plagiarism, more or less shameless depending of the number of modifications that have been made on the original source.

For instance, the following text:
\begin{quote}
   Dans le monde réel, très rares sont les situations où l'on serait capable d'effectuer une partition nette d'un ensemble d'objets en des parties disjointes, voire même aux frontières clairement établies. La gradualité du passage entre des classes différentes aux frontières non reconnaissables n'est-elle pas l'une des motivations essentielles, sinon la première, qui furent à l'origine de la naissance de la théorie des sous-ensembles flous. Les techniques floues de classification sont souvent nées de la tentative de généralisation de techniques déjà existantes d'après \cite{Khodja-97}.
\end{quote}
is an awkward ``quotation'' of:
\begin{quote}
   \emph{<< En effet, dans le monde réel qui nous entoure, très rares sont les situations où l'on serait capable d'effectuer une partition nette d'un ensemble d'objets en des parties disjointes, voire même aux frontières clairement établies. La gradualité du passage entre des classes différentes aux frontières non reconnaissables n'est-elle pas l'une des motivations essentielles, sinon la première, qui furent à l'origine de la naissance de la théorie des sous-ensembles flous [ZAD65]. L'introduction du concept de fonction d'appartenance dans des techniques de classification, et ce, très rapidement après la parution de l'article séminal de Zadeh, et les différents travaux qui le suivirent, témoignent de la fertilité de l'apport de la théorie des sous-ensembles flous au vaste champ de la classification, qui y trouve un cadre beaucoup plus naturel que celui offert par la théorie classique des ensembles. >>} \cite{Khodja-97}
\end{quote}

In fact, the first ``quotation'' makes the reader presume that this a point of view shared by several authors rather than really a quote.
Besides, the reference is associated to the last sentence rather the whole paragraph.

\bigskip

As another example, the following text:
\begin{quote}
La problématique de l'intégration repose sur la standardisation de données internes à l'entreprise, mais aussi des données externes.

Si on prend l'exemple d'une entreprise on aura besoin de ses données internes et externes c'est-à-dire celles des clients et fournisseurs de cette entreprise.

Ce n'est qu'avec une bonne intégration que l'on peut offrir une vision homogène, complète et véritablement transverse de l'entreprise. Pour cela il faut que le système d'information de l'entreprise soit parfaitement structuré, maîtrisé et d'un bon niveau d'intégration. Si tel n'est pas le cas, l'entrepôt de données ne pourra pas être mis en \oe uvre à cause de la qualité des données qui reste mauvaise.
\end{quote}
is not only a plagiarism but moreover a voluntary plagiarism with some kind of dissimulation:
\begin{quote}
\emph{<< La problématique de l'intégration repose sur la standardisation de données internes à l'entreprise, mais aussi des données externes (provenant par exemple de clients ou de fournisseurs).}

\emph{Ce n'est qu'au prix d'une intégration poussée que l'on peut offrir une vision homogène et véritablement transverse de l'entreprise. Ce[la] suppose que le système d'information de l'entreprise en amont soit bien structuré, bien maîtrisé, et bénéficie déjà d'un niveau d'intégration suffisant. Si tel n'est pas le cas, la mauvaise qualité des données peut empêcher la mise en \oe uvre de l'entrepôt de données. >>}\footnote{\emph{Entrepôt de données}. Wikipedia, 3 février 2010, \url{http://fr.wikipedia.org/wiki/Entrepôt_de_données}}
\end{quote}

\vspace{2\baselineskip}

In short, ``copy-and-paste'' operations are allowed under strict and restrictive conditions that:
\begin{itemize}
   \item they must be perfectly identifiable;
   \item the original references must be provided in the bibliography or as footnotes;
   \item they must be short;
   \item they must not be numerous.
\end{itemize}

In contrast, it is possible, and even highly recommended, to \emph{reformulate} with your own words and within the context of the report, the \emph{ideas} that have been found in the literature.  In that case, intellectual honesty is ``limited'' to adding the references to the sources in the text.

\bigskip

\begin{center}
   \fcolorbox{red}{yellow}{
      \color{red}
      \large
      \begin{minipage}[c]{0.8\columnwidth}
         Violators of these rules will be prosecuted in front of the disciplinary committee of the university.

         A fraud leads to the cancellation of the project, at the very least, up to the expulsion from the university as well as the prohibition to pass a public exam for five years!
      \end{minipage}
   }
\end{center}

\chapter{Reminder}
\label{app:Reminder}

A reminder appendix can contain information that is supposed to be known by the reader but that is worth to include in the report in order to make it self-contained.

If the reminder contains only a list of short definitions, consider naming it ``Glossary'' instead.  You can have both.

For instance, we can write down: ``The average can be computed differently whether the individuals are grouped or not, their exact number known or only their frequency, i.e.:
\begin{eqnarray}
    \mu & = & \frac{1}{n} \sum_{i=1}^n x_i\\
    \mu & = & \frac{1}{N} \sum_{i=1}^m x_i \times n_i\\
    \mu & = & \sum_{i=1}^m x_i \times f_i
\end{eqnarray}
with:
\begin{itemize}
    \item $N = \sum_{i=1}^m n_i$ ;
    \item $f_i = \frac{n_i}{N}$.''
\end{itemize}

\chapter{Detailed Measures}
\label{app:Measures}

Lengthy sub-results have to be put in appendices.  In other words, too boring details should be postponed to the very last part of the reading, that is when the reader is interested enough in understanding the very details of your proposal, especially if he or she intend to reproduce your experiment.  This is also true for detailed algorithms, etc.

This (these) appendix(ces) is (are) mandatory in order for the report to contain of the ``proofs'' of its claims, i.e., to really provide a \emph{scientific} work.

\chapter{Annotated References}
\label{app:FichesLecture}

It is a good idea to provide a short summary of each of the papers in the references.

For each paper or book (in rare cases a \emph{complete and persistent} web site), you should extract the following kind of information:  firstly, a short summary;  then, your own analysis.

This is slightly redundant with the state-of-the-art chapter. However, notice that it lacks the overall synthesis, and it focuses on a single paper at a time.  In fact, this greatly helps to achieve the state-of-the-art.

\paragraph{\emph{Title of a paper}.}

Describe rapidly what problem is attacked in the paper (add the reference, e.g. \cite{Pascal-1671}).

\subparagraph{Summary.}

The summary presents the main idea of the paper and the work conducted \emph{by the authors} up to their conclusions.

\subparagraph{Analysis.}

It is only during a second phase that you can analyse the contents of the paper, i.e., verify it (errors are always possible in the scientific literature!), express your opinion about the advances claimed by the paper, and establish a connection with your own work.

\paragraph{\emph{Title of a paper}.}

Etc.

\chapter{Schedule}

This appendix is \emph{mandatory}.

Figure~\ref{fig:Drafting} shows the draft schedule establish \emph{a priori}\ldots

\begin{figure*}
% - Use the starred version in order to put floats on two columns
% - Possibly, use the "\ifscreen ... \else ... \fi"" alternative to orientate correctly
%   the planning with respect to the orientation of the paper (cf. below for the auto-evaluation)
   \centering
      \emph{<Insert a Gantt's diagram.>}
   \caption{Drafting}
   \label{fig:Drafting}
\end{figure*}

Figure~\ref{fig:Planning} introduce the planning that has been build week after week during the course of the work.

\begin{figure*}
   \centering
      \emph{<Insert a Gantt's diagram.>}
   \caption{Planning}
   \label{fig:Planning}
\end{figure*}

Discuss differences between the drafting and the planning as well as lessons learned on the management of a research project or R\&D project.

\chapter{Weekly Reports}
\label{ann:WeeklyReports}

This appendix is \emph{mandatory}.

\begin{fichesuivi}{September 13, 2010}{September 18, 2010}
   \tempstravailA{2}{30}
   \tempstravailB{3}{45}

   \begin{travaileffectue}
      \begin{itemize}
         \item Task 1:  difficulty, simplicity; achieved, advanced up to $t$\%; etc.;
         \item Task 2:  \ldots;
         \item Etc.
      \end{itemize}
   \end{travaileffectue}

   \begin{travailnoneffectue}
      \begin{itemize}
         \item Task 1:  reasons; postponements, cancellations; etc.;
         \item Task 2:  \ldots;
         \item Etc.
      \end{itemize}
   \end{travailnoneffectue}

   \begin{echange}
      \begin{itemize}
         \item Questions;
         \item Answers;
         \item Clarification, comprehension;
         \item Choices, orientations, reorientations;
         \item Etc.
      \end{itemize}
   \end{echange}

   \begin{planification}
      \begin{itemize}
         \item Researches to be conducted;
         \item Papers to be read, understood, and analysed;
         \item Codes to develop;
         \item Etc.
      \end{itemize}
   \end{planification}
\end{fichesuivi}

\begin{fichesuivi}{September 20, 2010}{September 24, 2010}
   \tempstravailA{7}{50}
   \tempstravailB{5}{45}

   \begin{travaileffectue}
   \end{travaileffectue}

   \begin{travailnoneffectue}
   \end{travailnoneffectue}

   \begin{echange}
   \end{echange}

   \begin{planification}
   \end{planification}
\end{fichesuivi}

\begin{fichesuivi}{September 27, 2010}{October 1st, 2010}
   \tempstravailA{11}{20}
   \tempstravailB{9}{55}

   \begin{travaileffectue}
   \end{travaileffectue}

   \begin{travailnoneffectue}
   \end{travailnoneffectue}

   \begin{echange}
   \end{echange}

   \begin{planification}
   \end{planification}
\end{fichesuivi}

\begin{fichesuivi}{}{}
   \tempstravailA{14}{30}
   \tempstravailB{9}{20}

   \begin{travaileffectue}
   \end{travaileffectue}

   \begin{travailnoneffectue}
   \end{travailnoneffectue}

   \begin{echange}
   \end{echange}

   \begin{planification}
   \end{planification}
\end{fichesuivi}

\begin{fichesuivi}{}{}
   \tempstravailA{12}{30}
   \tempstravailB{3}{40}

   \begin{travaileffectue}
   \end{travaileffectue}

   \begin{travailnoneffectue}
   \end{travailnoneffectue}

   \begin{echange}
   \end{echange}

   \begin{planification}
   \end{planification}
\end{fichesuivi}

\begin{fichesuivi}{}{}
   \tempstravailA{7}{10}
   \tempstravailB{14}{30}

   \begin{travaileffectue}
   \end{travaileffectue}

   \begin{travailnoneffectue}
   \end{travailnoneffectue}

   \begin{echange}
   \end{echange}

   \begin{planification}
   \end{planification}
\end{fichesuivi}

\begin{fichesuivi}{}{}
   \tempstravailA{9}{15}
   \tempstravailB{13}{45}

   \begin{travaileffectue}
   \end{travaileffectue}

   \begin{travailnoneffectue}
   \end{travailnoneffectue}

   \begin{echange}
   \end{echange}

   \begin{planification}
   \end{planification}
\end{fichesuivi}

\begin{fichesuivi}{}{}
   \tempstravailA{18}{40}
   \tempstravailB{1}{25}

   \begin{travaileffectue}
   \end{travaileffectue}

   \begin{travailnoneffectue}
   \end{travailnoneffectue}

   \begin{echange}
   \end{echange}

   \begin{planification}
   \end{planification}
\end{fichesuivi}

\begin{fichesuivi}{}{}
   \tempstravailA{21}{40}
   \tempstravailB{17}{10}

   \begin{travaileffectue}
   \end{travaileffectue}

   \begin{travailnoneffectue}
   \end{travailnoneffectue}

   \begin{echange}
   \end{echange}

   \begin{planification}
   \end{planification}
\end{fichesuivi}

\begin{fichesuivi}{}{}
   \tempstravailA{4}{30}
   \tempstravailB{8}{15}

   \begin{travaileffectue}
   \end{travaileffectue}

   \begin{travailnoneffectue}
   \end{travailnoneffectue}

   \begin{echange}
   \end{echange}

   \begin{planification}
   \end{planification}
\end{fichesuivi}

\begin{fichesuivi}{}{}
   \tempstravailA{10}{10}
   \tempstravailB{11}{00}

   \begin{travaileffectue}
   \end{travaileffectue}

   \begin{travailnoneffectue}
   \end{travailnoneffectue}

   \begin{echange}
   \end{echange}

   \begin{planification}
   \end{planification}
\end{fichesuivi}

\begin{fichesuivi}{}{}
   \tempstravailA{3}{30}
   \tempstravailB{2}{10}

   \begin{travaileffectue}
   \end{travaileffectue}

   \begin{travailnoneffectue}
   \end{travailnoneffectue}

   \begin{echange}
   \end{echange}

   \begin{planification}
   \end{planification}
\end{fichesuivi}

\begin{fichesuivi}{}{}
   \tempstravailA{10}{00}
   \tempstravailB{10}{00}

   \begin{travaileffectue}
   \end{travaileffectue}

   \begin{travailnoneffectue}
   \end{travailnoneffectue}

   \begin{echange}
   \end{echange}

   \begin{planification}
   \end{planification}
\end{fichesuivi}

\begin{fichesuivi}{}{}
   \tempstravailA{3}{45}
   \tempstravailB{10}{20}

   \begin{travaileffectue}
   \end{travaileffectue}

   \begin{travailnoneffectue}
   \end{travailnoneffectue}

   \begin{echange}
   \end{echange}

   \begin{planification}
   \end{planification}
\end{fichesuivi}

\begin{fichesuivi}{}{}
   \tempstravailA{16}{30}
   \tempstravailB{18}{15}

   \begin{travaileffectue}
   \end{travaileffectue}

   \begin{travailnoneffectue}
   \end{travailnoneffectue}

   \begin{echange}
   \end{echange}

   \begin{planification}
   \end{planification}
\end{fichesuivi}

\begin{fichesuivi}{}{}
   \tempstravailA{14}{30}
   \tempstravailB{22}{30}

   \begin{travaileffectue}
   \end{travaileffectue}

   \begin{travailnoneffectue}
   \end{travailnoneffectue}

   \begin{echange}
   \end{echange}

   \begin{planification}
   \end{planification}
\end{fichesuivi}

\begin{fichesuivi}{}{}
   \tempstravailA{17}{45}
   \tempstravailB{12}{50}

   \begin{travaileffectue}
   \end{travaileffectue}

   \begin{travailnoneffectue}
   \end{travailnoneffectue}

   \begin{echange}
   \end{echange}

   \begin{planification}
   \end{planification}
\end{fichesuivi}

\begin{fichesuivi}{}{}
   \tempstravailA{13}{10}
   \tempstravailB{9}{30}

   \begin{travaileffectue}
   \end{travaileffectue}

   \begin{travailnoneffectue}
   \end{travailnoneffectue}

   \begin{echange}
   \end{echange}

   \begin{planification}
   \end{planification}
\end{fichesuivi}

The summary table of work dedicated to the project is \emph{mandatory}.
If you do not use the provided weekly report sheets, you must establish the summary by yourself.
Otherwise, the simple command that follows in the source code (\verb+\printweeksummary+) does all the job of generating the table along with all the hyperlinks to the weekly reports.

\printweeksummary

\chapter{Self-assessment}

This appendix is \emph{mandatory}.

Figure~\ref{fig:IntermediateAutoEvaluation} enumerates a number of important points related to the three aspects of the work:
\begin{enumerate}
   \item report;
   \item oral presentation;
   \item results.
\end{enumerate}
This allows to evaluation your own level of satisfcation at the end of the first part of the project, consisting of:
\begin{enumerate}
   \item preliminary study;
   \item bibliographic study;
   \item general design of a solution.
\end{enumerate}

You can discuss in some details these various points.

\begin{figure*}
   \centering
      \ifscreen % macro TeX (issue de la classe report-rd-info.cls) permettant d'ajuster le contenu en fonction du l'orientation du document (<< screen >> ou pas)
         \rotatebox{90}{\includegraphics[width=0.9\textheight]{Images/Grille-Evaluation-PRD1}}
      \else
         \includegraphics[width=0.9\textwidth]{Images/Grille-Evaluation-PRD1}
      \fi
   \caption{Points à contrôler à l'issue de la phase I}
   \label{fig:IntermediateAutoEvaluation}
\end{figure*}

Figure~\ref{fig:FinalAutoEvaluation} provides the same kind of evaluation for the second part of the project, i.e.:
\begin{enumerate}
   \item detailed design;
   \item development;
   \item receipt.
\end{enumerate}

\begin{figure*}
   \centering
      \ifscreen
         \rotatebox{90}{\includegraphics[width=0.9\textheight]{Images/Grille-Evaluation-PRD2}}
      \else
         \includegraphics[width=0.9\textwidth]{Images/Grille-Evaluation-PRD2}
      \fi
   \caption{Points à contrôler à l'issue de la phase II}
   \label{fig:FinalAutoEvaluation}
\end{figure*}

\end{document}
